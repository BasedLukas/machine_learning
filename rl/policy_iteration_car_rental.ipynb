{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import math\n",
    "from types import SimpleNamespace as sn\n",
    "from tqdm import tqdm\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.stats import poisson\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def poisson_pmf(lambd: float, n: int) -> float:\n",
    "    \"\"\"\n",
    "    Calculate the Poisson probability of observing n events.\n",
    "    \n",
    "    :param lambd: The expected number of occurrences (rate parameter).\n",
    "    :param n: The actual number of occurrences.\n",
    "    :return: The probability of observing n events.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        probability = (math.exp(-lambd) * lambd**n) / math.factorial(n)\n",
    "        return probability\n",
    "    except (OverflowError, ValueError):\n",
    "        # If n is too large, math.factorial(n) will raise an OverflowError\n",
    "        # If lambd or n is negative, it will raise a ValueError\n",
    "        print(\"Error: The input values are not valid.\")\n",
    "        return 0\n",
    "\n",
    "def all_states():\n",
    "    \"\"\"returns an iterator of all possible states (n_cars_a, n_cars_b)\"\"\"\n",
    "    states = []\n",
    "    for n_cars_a in range(MAX_CARS_AT_LOCATION + 1):\n",
    "        for n_cars_b in range(MAX_CARS_AT_LOCATION + 1):\n",
    "            states.append((n_cars_a, n_cars_b))\n",
    "    #shuffle the states to make the learning more robust\n",
    "    random.shuffle(states)\n",
    "    return states\n",
    "\n",
    "def simulate_environment(n_cars_a, n_cars_b, action):\n",
    "    \"\"\"\"Simulate the environment for a given state and action. Return a list of (cars_a, cars_b, reward, probability) tuples.\"\"\"\n",
    "\n",
    "    max_requests_a = np.ceil(LAMBDA_REQUESTS_A + 3 * np.sqrt(LAMBDA_REQUESTS_A)).astype(int)\n",
    "    max_requests_b = np.ceil(LAMBDA_REQUESTS_B + 3 * np.sqrt(LAMBDA_REQUESTS_B)).astype(int)\n",
    "    max_returns_a = np.ceil(LAMBDA_RETURNS_A + 3 * np.sqrt(LAMBDA_RETURNS_A)).astype(int)\n",
    "    max_returns_b = np.ceil(LAMBDA_RETURNS_B + 3 * np.sqrt(LAMBDA_RETURNS_B)).astype(int)\n",
    "\n",
    "    all_transitions = []\n",
    "\n",
    "    for requested_a in range(max_requests_a+1):\n",
    "        for requested_b in range(max_requests_b+1):\n",
    "            for returned_a in range(max_returns_a+1):\n",
    "                for returned_b in range(max_returns_b+1):\n",
    "                    prob_request_a = poisson_pmf(LAMBDA_REQUESTS_A, requested_a)\n",
    "                    prob_request_b = poisson_pmf(LAMBDA_REQUESTS_B, requested_b)\n",
    "                    prob_return_a = poisson_pmf(LAMBDA_RETURNS_A, returned_a)\n",
    "                    prob_return_b = poisson_pmf(LAMBDA_RETURNS_B, returned_b)\n",
    "\n",
    "                    probability = prob_request_a * prob_request_b * prob_return_a * prob_return_b\n",
    "                    # calculate profit, ensure we dont rent more cars than we have\n",
    "                    cars_rented_a = min(requested_a, n_cars_a)\n",
    "                    cars_rented_b = min(requested_b, n_cars_b)\n",
    "                    daily_profit = (cars_rented_a + cars_rented_b) * PROFIT_PER_CAR_RENTED\n",
    "\n",
    "                    # update car counts\n",
    "                    n_cars_a = min(n_cars_a - cars_rented_a + returned_a, MAX_CARS_AT_LOCATION)\n",
    "                    n_cars_b = min(n_cars_b - cars_rented_b + returned_b, MAX_CARS_AT_LOCATION)\n",
    "\n",
    "                    # Calculate the number of cars after moving them, without modifying n_cars_a and n_cars_b\n",
    "                    if action > 0:\n",
    "                        cars_moved = min(action, n_cars_a, MAX_CARS_AT_LOCATION - n_cars_b)\n",
    "                    elif action < 0:\n",
    "                        cars_moved = min(-action, n_cars_b, MAX_CARS_AT_LOCATION - n_cars_a)\n",
    "                    else:\n",
    "                        cars_moved = 0\n",
    "\n",
    "                        \n",
    "                    # Calculate new state without modifying the original state\n",
    "                    new_n_cars_a = n_cars_a - cars_moved if action > 0 else n_cars_a + abs(action)\n",
    "                    new_n_cars_b = n_cars_b + cars_moved if action > 0 else n_cars_b - abs(action)\n",
    "\n",
    "                    # Ensure the new state is within the max car constraints\n",
    "                    new_n_cars_a = int(min(max(new_n_cars_a, 0), MAX_CARS_AT_LOCATION))\n",
    "                    new_n_cars_b = int(min(max(new_n_cars_b, 0), MAX_CARS_AT_LOCATION))\n",
    "\n",
    "                    daily_profit -= abs(cars_moved) * COST_PER_CAR_MOVED\n",
    "                    all_transitions.append((new_n_cars_a, new_n_cars_b, daily_profit, probability))\n",
    "    \n",
    "    return all_transitions\n",
    "\n",
    "# def sample_transition(n_cars_a, n_cars_b, action):\n",
    "#     # Sample the number of requests and returns for both locations\n",
    "#     requests_a = poisson.rvs(LAMBDA_REQUESTS_A)\n",
    "#     requests_b = poisson.rvs(LAMBDA_REQUESTS_B)\n",
    "#     returns_a = poisson.rvs(LAMBDA_RETURNS_A)\n",
    "#     returns_b = poisson.rvs(LAMBDA_RETURNS_B)\n",
    "\n",
    "#     # Calculate rented cars, ensuring we don't rent more than we have\n",
    "#     cars_rented_a = min(requests_a, n_cars_a)\n",
    "#     cars_rented_b = min(requests_b, n_cars_b)\n",
    "    \n",
    "#     # Calculate the reward (profit from renting)\n",
    "#     reward = (cars_rented_a + cars_rented_b) * PROFIT_PER_CAR_RENTED\n",
    "\n",
    "#     # Move cars\n",
    "#     if action > 0:\n",
    "#         cars_moved = min(action, n_cars_a, MAX_CARS_AT_LOCATION - n_cars_b)\n",
    "#     elif action < 0:\n",
    "#         cars_moved = min(-action, n_cars_b, MAX_CARS_AT_LOCATION - n_cars_a)\n",
    "#     else:\n",
    "#         cars_moved = 0\n",
    "    \n",
    "#     # Update the number of cars for each location after moving them\n",
    "#     new_n_cars_a = n_cars_a - cars_moved if action > 0 else n_cars_a + abs(action)\n",
    "#     new_n_cars_b = n_cars_b + cars_moved if action > 0 else n_cars_b - abs(action)\n",
    "    \n",
    "#     # Ensure new car counts do not exceed location capacity or fall below zero\n",
    "#     new_n_cars_a = max(min(new_n_cars_a + returns_a - cars_rented_a, MAX_CARS_AT_LOCATION), 0)\n",
    "#     new_n_cars_b = max(min(new_n_cars_b + returns_b - cars_rented_b, MAX_CARS_AT_LOCATION), 0)\n",
    "    \n",
    "#     # Update the reward with the cost of moving cars\n",
    "#     reward -= abs(cars_moved) * COST_PER_CAR_MOVED\n",
    "\n",
    "#     # No need for probability as we are sampling directly\n",
    "#     return new_n_cars_a, new_n_cars_b, reward\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "MAX_CARS_AT_LOCATION = 20\n",
    "MAX_CARS_MOVED = 5\n",
    "COST_PER_CAR_MOVED = 2\n",
    "PROFIT_PER_CAR_RENTED = 10\n",
    "LAMBDA_REQUESTS_A = 3\n",
    "LAMBDA_RETURNS_A = 3\n",
    "LAMBDA_REQUESTS_B = 4\n",
    "LAMBDA_RETURNS_B = 2\n",
    "GAMMA = 0.9\n",
    "THETA = 1\n",
    "\n",
    "policy = np.random.randint(-MAX_CARS_MOVED,MAX_CARS_MOVED,size=(MAX_CARS_AT_LOCATION + 1, MAX_CARS_AT_LOCATION + 1)) \n",
    "value = np.random.randint(-500,500, size=(MAX_CARS_AT_LOCATION + 1, MAX_CARS_AT_LOCATION + 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def policy_evaluation():\n",
    "\n",
    "    while True:\n",
    "        delta = 0\n",
    "        for n_cars_a, n_cars_b in all_states():\n",
    "\n",
    "            old_value = value[n_cars_a][ n_cars_b]\n",
    "            action = policy[n_cars_a][ n_cars_b]\n",
    "            \n",
    "            # Get the list of all possible next states, rewards and probabilities\n",
    "            transitions = simulate_environment(n_cars_a, n_cars_b, action)\n",
    "\n",
    "            # Calculate the new value estimate\n",
    "            new_value = 0\n",
    "\n",
    "            for (next_n_cars_a, next_n_cars_b, reward, prob) in transitions:\n",
    "                state_value = value[next_n_cars_a][next_n_cars_b]\n",
    "                state_value = (state_value * GAMMA) + reward\n",
    "                new_value += prob * state_value\n",
    "\n",
    "            # Update the value function\n",
    "            value[n_cars_a][ n_cars_b] = new_value\n",
    "            delta = max(delta, abs(old_value - new_value))\n",
    "\n",
    "        print(\"Delta: \", delta)\n",
    "        if delta < THETA:\n",
    "            break\n",
    "\n",
    "\n",
    "def policy_improvement():\n",
    "    policy_stable = True\n",
    "    for n_car_a, n_car_b in all_states():\n",
    "        old_action = policy[n_car_a][n_car_b]\n",
    "        best_action_value = float('-inf')  # Reset the best action value for each state\n",
    "        best_action = None\n",
    "\n",
    "        # Evaluate each action's expected return\n",
    "        for action in range(-MAX_CARS_MOVED, MAX_CARS_MOVED + 1):\n",
    "            transitions = simulate_environment(n_car_a, n_car_b, action)\n",
    "            action_value = 0\n",
    "\n",
    "            # Calculate expected return for this action\n",
    "            for (next_n_cars_a, next_n_cars_b, reward, prob) in transitions:\n",
    "                state_value = value[next_n_cars_a][next_n_cars_b]\n",
    "                action_value += prob * (reward + GAMMA * state_value)\n",
    "                print(\"Action value: \", action_value, \"best action value\", best_action_value)\n",
    "            # Update best action if this action is better than the current best\n",
    "            if action_value > best_action_value:\n",
    "                best_action = action\n",
    "                best_action_value = action_value\n",
    "\n",
    "        # Update the policy if a better action was found\n",
    "        if best_action is not None and old_action != best_action:\n",
    "            print(\"Policy changed for state: \", n_car_a, n_car_b, \" from \", old_action, \" to \", best_action)\n",
    "            policy_stable = False\n",
    "            policy[n_car_a][n_car_b] = best_action\n",
    "        else:\n",
    "            print(\"Policy stable for state: \", n_car_a, n_car_b)\n",
    "            print(\"Old action: \", old_action)\n",
    "            print(\"Best action: \", best_action)\n",
    "            print(\"Best action value: \", best_action_value)\n",
    "\n",
    "\n",
    "    return policy_stable\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "policy_improvement()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    policy_evaluation()\n",
    "    if policy_improvement():\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_policy(policy_matrix: np.ndarray):\n",
    "    \"\"\"\n",
    "    Plot the optimal policy as a contour plot.\n",
    "\n",
    "    Parameters:\n",
    "    - policy_matrix: A numpy matrix representing the policy, where each entry policy_matrix[i, j] is the\n",
    "                     optimal action to take in state (i, j).\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(7, 7))\n",
    "    plt.contourf(policy_matrix, levels=np.arange(-5, 6), cmap='jet')\n",
    "    plt.colorbar()\n",
    "    plt.title('Optimal Policy ($\\pi^*$)')\n",
    "    plt.xlabel('# Cars at first location')\n",
    "    plt.ylabel('# Cars at second location')\n",
    "    plt.show()\n",
    "\n",
    "plot_policy(policy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_value_function(value_matrix: np.ndarray):\n",
    "    \"\"\"\n",
    "    Plot the value function as a 3D surface plot.\n",
    "\n",
    "    Parameters:\n",
    "    - value_matrix: A numpy matrix representing the value function, where each entry value_matrix[i, j]\n",
    "                    is the value of the state (i, j).\n",
    "    \"\"\"\n",
    "    fig = plt.figure(figsize=(12, 7))\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    X = np.arange(0, value_matrix.shape[0], 1)\n",
    "    Y = np.arange(0, value_matrix.shape[1], 1)\n",
    "    X, Y = np.meshgrid(X, Y)\n",
    "    ax.plot_surface(X, Y, value_matrix, cmap='viridis')\n",
    "    ax.set_title('Value Function $V^{\\pi^*}$')\n",
    "    ax.set_xlabel('# Cars at first location')\n",
    "    ax.set_ylabel('# Cars at second location')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_value_function(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "policy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
